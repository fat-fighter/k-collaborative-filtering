{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/fat-fighter/Documents/cs771-project/hybrid-method/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Description of Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: features\n",
    "\n",
    "- **tracks-mfcc.csv** - Contains already extracted mfcc features from all tracks using 30-60 seconds of tracks\n",
    "- **tracks-cluster-probabilities.csv** - Contains the cluster probabolities and assignments for all tracks (based on their mfcc features_\n",
    "- **timbres-cluster-probabilities.csv** - Contains the cluster probabilities and assignments for all segment timbres of all tracks\n",
    "- **tracks-collective-timbres-clusters-features.csv** - Contains the extracted features of a track using its timbres' collective cluster probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: million-song-subset\n",
    "\n",
    "- **tracks-features.csv** - Contains mfcc features extracted from tracks in the MSS\n",
    "- **tracks-timbres.csv** - Contains segment timbres for all tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: taste-profile-subset\n",
    "\n",
    "- **songs.txt** - A list of song ids\n",
    "- **users.txt** - A list of user ids\n",
    "- **train-triplets.txt** - A user-song-count triplets\n",
    "- **song-to-tracks.txt** - A song-track id mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering Tracks (Based on Tracks' MFCC Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_mfcc = pd.read_csv(\n",
    "    root_path + \"hybrid-method/data/features/tracks-mfcc.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_mfcc = 13\n",
    "n_clusters = 10\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(\n",
    "    n_components=n_clusters, covariance_type='diag', max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"av\" + str(i) for i in range(1, n_mfcc + 1)] + [\"sd\" + str(i) for i in range(1, n_mfcc + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(tracks_mfcc[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "probs = estimator.predict_proba(tracks_mfcc[cols])\n",
    "clusters = estimator.predict(tracks_mfcc[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"id\"] + [\"k\" + str(k) for k in range(1, n_clusters + 1)] + [\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile = root_path + \"hybrid-method/data/features/tracks-cluster-probabilities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(outfile, \"w\") as f:\n",
    "    f.write(\"\\t\".join(cols) + \"\\n\")\n",
    "    for i, song_id in enumerate(tracks_mfcc[\"id\"]):\n",
    "        params = [song_id] + list(probs[i]) + [clusters[i]]\n",
    "\n",
    "        params = [str(param) for param in params]\n",
    "\n",
    "        f.write(\"\\t\".join(params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mapping Users to Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/taste-profile-subset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "songs_to_tracks = dict()\n",
    "count = 0\n",
    "with open(local_path + \"songs-to-tracks.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) > 1:\n",
    "            songs_to_tracks[line[0]] = line[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile = open(local_path + \"user-track-counts.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(local_path + \"user-song-counts.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 3 and line[1] in songs_to_tracks:\n",
    "            for track in songs_to_tracks[line[1]]:\n",
    "                outfile.write(\"\\t\".join([line[0], track, line[2]]) + \"\\n\")\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing User Features (Based on Tracks' Cluster Probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/\"\n",
    "\n",
    "n_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_mfcc = dict()\n",
    "with open(local_path + \"features/tracks-cluster-probabilities.csv\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = f.readline()\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 12:\n",
    "            tracks_mfcc[line[0]] = np.array([float(field) for field in line[1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = dict()\n",
    "user_track_counts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(local_path + \"taste-profile-subset/user-track-counts.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 3 and line[1] in tracks_mfcc:\n",
    "            if line[0] not in user_track_counts:\n",
    "                user_features[line[0]] = np.zeros(n_clusters)\n",
    "                user_track_counts[line[0]] = 0\n",
    "                \n",
    "            user_features[line[0]] += tracks_mfcc[line[1]]\n",
    "            user_track_counts[line[0]] += 1\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = local_path + \"features/user-features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outfile, \"w\") as f:\n",
    "    for user in user_features:\n",
    "        f.write(\"\\t\".join([user] + [str(field) for field in (user_features[user] / float(user_track_counts[user]))]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Users (Based on Users' Computed Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(local_path + \"user-features.csv\", sep=\"\\t\")\n",
    "\n",
    "timbres_col_list = [\"t1\", \"t2\", \"t3\", \"t4\", \"t5\",\n",
    "                    \"t6\", \"t7\", \"t8\", \"t9\", \"t10\", \"t11\", \"t12\"]\n",
    "timbres_data = timbres[timbres_col_list]\n",
    "\n",
    "n_clusters = 10\n",
    "estimators = dict(\n",
    "    (cov_type, GaussianMixture(\n",
    "        n_components=n_clusters,\n",
    "        covariance_type=cov_type,\n",
    "        max_iter=1000,\n",
    "        random_state=0))\n",
    "    for cov_type in ['spherical', 'diag', 'tied'])\n",
    "\n",
    "\n",
    "for index, (name, estimator) in enumerate(estimators.items()):\n",
    "    print \"Running GMM with covariance matrix type:\", name\n",
    "    estimator.fit(timbres_data)\n",
    "    print \"\\tEstimator Learned\"\n",
    "    probs = estimator.predict_proba(timbres_data)\n",
    "    with open(\"data/\" + name + \"-songs-timbres-cluster-probabilities.csv\", \"w\") as f:\n",
    "        for i, song_id in enumerate(timbres[\"id\"]):\n",
    "            params = [song_id]\n",
    "            params.extend(probs[i])\n",
    "\n",
    "            params = [str(param) for param in params]\n",
    "\n",
    "            f.write(\"\\t\".join(params) + \"\\n\")\n",
    "\n",
    "    print \"\\tObserved AIC Value:\", estimator.aic(timbres_data), \"\\n\""
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "opencv"
  },
  "kernelspec": {
   "display_name": "Python 2.7 for CS771: Project",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
