{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/fat-fighter/Documents/cs771-project/hybrid-method/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Description of Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: features\n",
    "\n",
    "- **tracks-mfcc.csv** - Contains already extracted mfcc features from all tracks using 30-60 seconds of tracks\n",
    "- **tracks-cluster-probabilities.csv** - Contains the cluster probabolities and assignments for all tracks (based on their mfcc features_\n",
    "- **timbres-cluster-probabilities.csv** - Contains the cluster probabilities and assignments for all segment timbres of all tracks\n",
    "- **tracks-collective-timbres-clusters-features.csv** - Contains the extracted features of a track using its timbres' collective cluster probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: million-song-subset\n",
    "\n",
    "- **tracks-features.csv** - Contains mfcc features extracted from tracks in the MSS\n",
    "- **tracks-timbres.csv** - Contains segment timbres for all tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Folder: taste-profile-subset\n",
    "\n",
    "- **songs.txt** - A list of song ids\n",
    "- **users.txt** - A list of user ids\n",
    "- **train-triplets.txt** - A user-song-count triplets\n",
    "- **song-to-tracks.txt** - A song-track id mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering Tracks (Based on Tracks' MFCC Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_mfcc = pd.read_csv(\n",
    "    root_path + \"hybrid-method/data/features/tracks-mfcc.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_mfcc = 13\n",
    "n_clusters = 10\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(n_components=n_clusters, covariance_type='diag', max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"av\" + str(i) for i in range(1, n_mfcc + 1)] + [\"sd\" + str(i) for i in range(1, n_mfcc + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(tracks_mfcc[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "probs = estimator.predict_proba(tracks_mfcc[cols])\n",
    "clusters = estimator.predict(tracks_mfcc[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"id\"] + [\"k\" + str(k) for k in range(1, n_clusters + 1)] + [\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile = root_path + \"hybrid-method/data/features/tracks-cluster-probabilities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(outfile, \"w\") as f:\n",
    "    f.write(\"\\t\".join(cols) + \"\\n\")\n",
    "    for i, song_id in enumerate(tracks_mfcc[\"id\"]):\n",
    "        params = [song_id] + list(probs[i]) + [clusters[i]]\n",
    "\n",
    "        params = [str(param) for param in params]\n",
    "\n",
    "        f.write(\"\\t\".join(params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mapping Users to Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/taste-profile-subset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "songs_to_tracks = dict()\n",
    "count = 0\n",
    "with open(local_path + \"songs-to-tracks.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) > 1:\n",
    "            songs_to_tracks[line[0]] = line[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile = open(local_path + \"user-track-counts.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(local_path + \"user-song-counts.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 3 and line[1] in songs_to_tracks:\n",
    "            for track in songs_to_tracks[line[1]]:\n",
    "                outfile.write(\"\\t\".join([line[0], track, line[2]]) + \"\\n\")\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Computing User Features (Based on Tracks' Cluster Probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/\"\n",
    "\n",
    "n_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_mfcc = dict()\n",
    "with open(local_path + \"features/tracks-cluster-probabilities.csv\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = f.readline()\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 12:\n",
    "            tracks_mfcc[line[0]] = np.array([float(field) for field in line[1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "user_features = dict()\n",
    "user_track_counts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(local_path + \"taste-profile-subset/user-track-counts.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        line = line.strip(\" \\t\\n\\r\").split()\n",
    "        if len(line) == 3 and line[1] in tracks_mfcc:\n",
    "            if line[0] not in user_track_counts:\n",
    "                user_features[line[0]] = np.zeros(n_clusters)\n",
    "                user_track_counts[line[0]] = 0\n",
    "                \n",
    "            user_features[line[0]] += tracks_mfcc[line[1]]\n",
    "            user_track_counts[line[0]] += 1\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outfile = local_path + \"features/user-features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(outfile, \"w\") as f:\n",
    "    for user in user_features:\n",
    "        f.write(\"\\t\".join([user] + [str(field) for field in (user_features[user] / float(user_track_counts[user]))]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Users (Based on Users' Computed Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = root_path + \"data/features/\"\n",
    "n_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(local_path + \"user-features.csv\", sep=\"\\t\", header=None)\n",
    "\n",
    "cols = user_data.columns.tolist()[1:]\n",
    "user_features = user_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(n_components=n_clusters, covariance_type='diag', max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=1000,\n",
       "        means_init=None, n_components=10, n_init=1, precisions_init=None,\n",
       "        random_state=0, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = estimator.predict_proba(user_features)\n",
    "clusters = estimator.predict(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tObserved AIC Value: -42927772.7076 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(local_path + \"user-cluster-probabilities.csv\", \"w\") as f:\n",
    "    for i, user in enumerate(user_data[0]):\n",
    "        params = [user] + list(probs[i]) + [clusters[i]]\n",
    "        \n",
    "        params = [str(param) for param in params]\n",
    "\n",
    "        f.write(\"\\t\".join(params) + \"\\n\")\n",
    "        count += 1\n",
    "\n",
    "print \"\\tObserved AIC Value:\", estimator.aic(user_features), \"\\n\""
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "opencv"
  },
  "kernelspec": {
   "display_name": "Python 2.7 for CS771: Project",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
